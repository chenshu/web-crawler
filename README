This is web crawler program

首先通过一个起始页进去，根据正则匹配url获取进一步抓取的详情页面
从详情页面再正则匹配url递归进行抓取(详情页面的url有可能需要动态抓取)
为了避免死循环抓取，页面分为已经抓取集合
抓取前判断是否已经存在到已经抓取集合
获取到的页面有过期时间，页面过期后重新抓取，需要判断是否已经更改(304)

python anzhi_spider.py
#redis db 2 flushdb
python anzhi_page_parser.py > anzhi_meta
python anzhi_download.py
sh upload.sh www.anzhi.com_apk > anzhi_upload
python tools.py anzhi

python hiapk_spider.py
python hiapk_detail_spider.py
#redis db 1 flushdb
python hiapk_page_parser.py > hiapk_meta
python hiapk_download.py
sh upload.sh static.apk.hiapk.com_apk > hiapk_upload
python tools.py hiapk
#find hiapk/ -regextype posix-egrep -regex '[^\.]+' -type f -exec rm -rf {} \;
python download_pic.py hiapk
sh upload2.sh /disk2/hiapk > hiapk_pic_upload
python tools2.py hiapk
